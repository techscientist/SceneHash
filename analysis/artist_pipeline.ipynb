{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7316\n"
     ]
    }
   ],
   "source": [
    "# Start with raw artist data (id, name, [{terms, freq}])\n",
    "# Create artist matrix (per city!)\n",
    "# Apply tf-idf --> ready for venue/ML pipeline\n",
    "import pickle\n",
    "import pymysql as mdb\n",
    "import numpy as np\n",
    "\n",
    "##### Define a few functions ##########\n",
    "\n",
    "def getIndex(element, my_list):\n",
    "    # Create a generator\n",
    "    gen = (i for i,x in enumerate(my_list) if x == element)\n",
    "    for i in gen:\n",
    "        return i\n",
    "\n",
    "# scales vector(list) so that entries sum to 1\n",
    "def norm1(v):\n",
    "    scaled_vector = []\n",
    "    total_A = float(sum(v))\n",
    "    for i in v:\n",
    "        scaled_vector.append(i/total_A)\n",
    "    return scaled_vector\n",
    "\n",
    "##### Open up pickle files ######\n",
    "\n",
    "artist_store1 = pickle.load( open( \"pickle_artists/artist_info_0_5k.pickle\", \"rb\" ) )\n",
    "artist_store2 = pickle.load( open( \"pickle_artists/artist_info_5k_10k.pickle\", \"rb\" ) )\n",
    "artist_store3 = pickle.load( open( \"pickle_artists/artist_info_10k_15k.pickle\", \"rb\" ) )\n",
    "artist_store4 = pickle.load( open( \"pickle_artists/artist_info_15k_20k.pickle\", \"rb\" ) )\n",
    "\n",
    "artist_store_all = artist_store1 + artist_store2 + artist_store3 + artist_store4\n",
    "\n",
    "#print artist_store_all[18]\n",
    "##### Create master list of unique genre names #######\n",
    "master_genre_map = []\n",
    "for artist in artist_store_all:\n",
    "    for term in artist[2:]:\n",
    "        if term['name'] not in master_genre_map:\n",
    "            master_genre_map.append(term['name'])\n",
    "\n",
    "\n",
    "master_artist_genre_freq = dict() # {'artist': np.array[]}\n",
    "\n",
    "for i in range(len(artist_store_all)):\n",
    "    # Initialize vector of zeroes for all genres\n",
    "    genre_vec = [0] * len(master_genre_map)\n",
    "    # Loop over genres, make vector of frequencies\n",
    "    for term in artist_store_all[i][2:]:\n",
    "        # Get index of genre in master_genre_map\n",
    "        indx = getIndex(term['name'], master_genre_map)\n",
    "        # Set corresponding vector entry to value of frequency\n",
    "        genre_vec[indx] = term['frequency']\n",
    "    # Set key to artist name, value is array of (normalized) freqs\n",
    "    master_artist_genre_freq[artist_store_all[i][1]] = np.array(norm1(genre_vec))\n",
    "\n",
    "#for key, val in master_artist_genre_freq.iteritems():\n",
    "#    print key, val\n",
    "print len(master_artist_genre_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "##### Create artist vectors/tfidf for ust one metro region ####\n",
    "\n",
    "# Create list of just artist in one metro region\n",
    "regional_subset = dict()\n",
    "regional_subset_id = dict()\n",
    "region = '17835' # LA=17835, SF=26330, Chicago=9426, SD=11086, CIN=22040\n",
    "city = 'LA'\n",
    "\n",
    "con = mdb.connect('localhost', 'root', '', 'scenehash', autocommit=True, charset='utf8', use_unicode=True) \n",
    "cur = con.cursor()\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SELECT artist_id, artist, metro_id FROM events WHERE metro_id = %s\" % (region))\n",
    "    all_events = cur.fetchall()\n",
    "    for a_id, a_name, metro in all_events[:]:\n",
    "        # Check for duplicates, then assign vector\n",
    "        if a_name not in regional_subset:\n",
    "            try:\n",
    "                regional_subset[a_name] = master_artist_genre_freq[a_name]\n",
    "                regional_subset_id[a_id] = master_artist_genre_freq[a_name]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "# OK, have dict of {artist: vector} for a metro region\n",
    "\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def tf(genre, artist):\n",
    "    return regional_subset[artist][getIndex(genre, master_genre_map)]\n",
    "\n",
    "def n_containing(genre, reg_list):\n",
    "    indx = getIndex(genre, master_genre_map)\n",
    "    return sum(1 for art, gvec in reg_list.iteritems() if gvec[indx] > 0)\n",
    "\n",
    "def idf(genre, reg_list):\n",
    "    return math.log(float(len(reg_list)) / (1 + n_containing(genre, reg_list)))\n",
    "\n",
    "idf_list = []\n",
    "for gnr in master_genre_map:\n",
    "    idf_list.append(idf(gnr, regional_subset))\n",
    "master_genre_idf = np.array(idf_list)\n",
    "\n",
    "# Let's update each artist freq with IDF:\n",
    "for artist in regional_subset.iterkeys():\n",
    "    regional_subset[artist] = regional_subset[artist]*master_genre_idf\n",
    "\n",
    "# regional_subset is ready for the venues!\n",
    "pickle.dump( master_genre_idf, open( city+\"/master_genre_idf.pickle\", \"wb\" ) )\n",
    "print \"Done.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of venue names = 667\n",
      "Total number of venue ids = 667\n",
      "Total number of master venues = 667\n",
      "Total number of lat/lons = 667\n",
      "Total number of genres = 1035\n",
      "Total number of artists = 3620\n",
      "Total number of events = 667\n",
      "Total number of good venues = 317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncur.execute(\"CREATE TABLE events\"\\n            \"(pid INT PRIMARY KEY AUTO_INCREMENT, \"\\n            \"evt_id INT, \"\\n            \"evt_name VARCHAR(400), \"\\n            \"venue_name VARCHAR(150), \"\\n            \"venue_id INT, \"\\n            \"city_name VARCHAR(50), \"\\n            \"metro_id INT, \"\\n            \"latitude VARCHAR(20), \"\\n            \"longitude VARCHAR(20), \"\\n            \"evt_url VARCHAR(200), \"\\n            \"artist VARCHAR(200), \"\\n            \"artist_id INT, \"\\n            \"artist_billing VARCHAR(100) ) \"\\n            )\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of just artist in one metro region\n",
    "regional_venue_set = dict()\n",
    "#region = '26330' # LA=17835, SF=26330, Chicago=9426, SD=11086\n",
    "\n",
    "# Storage stuff\n",
    "venue_list = []\n",
    "venue_count = dict()\n",
    "venue_ids = []\n",
    "locations = []\n",
    "event_ids = []\n",
    "\n",
    "con = mdb.connect('localhost', 'root', '', 'scenehash', autocommit=True, charset='utf8', use_unicode=True) \n",
    "cur = con.cursor()\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SELECT evt_id, venue_name, venue_id, artist, latitude, longitude FROM events WHERE metro_id = %s\" % (region))\n",
    "    all_events = cur.fetchall()\n",
    "    for evtid, ven_name, ven_id, artist_name, lat, lon in all_events:\n",
    "        # Check for duplicates, create zeroes if doesn't exist\n",
    "        if ven_name not in regional_venue_set:\n",
    "            venue_list.append(ven_name)\n",
    "            venue_count[ven_name] = 1\n",
    "            venue_ids.append(ven_id)\n",
    "            locations.append([lat,lon])\n",
    "            event_ids.append(evtid)\n",
    "            regional_venue_set[ven_name] = np.array([0.] * len(master_genre_map))\n",
    "        try:\n",
    "            regional_venue_set[ven_name] +=  regional_subset[artist_name]\n",
    "            venue_count[ven_name] += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "# Let's keep only those venue with 2 > events\n",
    "regional_good_venues = dict()\n",
    "for key, val in regional_venue_set.iteritems():\n",
    "    if venue_count[key] > 2:\n",
    "        regional_good_venues[key] = val\n",
    "\n",
    "\n",
    "#for key, val in regional_venue_set.iteritems():\n",
    "#    print key, val\n",
    "\n",
    "print \"Total number of venue names =\", len(venue_list)\n",
    "print \"Total number of venue ids =\", len(venue_ids)\n",
    "print \"Total number of master venues =\", len(regional_venue_set)\n",
    "print \"Total number of lat/lons =\", len(locations)\n",
    "print \"Total number of genres =\", len(master_genre_map)\n",
    "print \"Total number of artists =\", len(regional_subset)\n",
    "print \"Total number of events =\", len(event_ids)\n",
    "print \"Total number of good venues =\", len(regional_good_venues)\n",
    "pickle.dump( venue_list, open( city+\"/venue_list.pickle\", \"wb\" ) )\n",
    "pickle.dump( venue_ids, open( city+\"/venue_ids.pickle\", \"wb\" ) )\n",
    "pickle.dump( locations, open( city+\"/locations.pickle\", \"wb\" ) )\n",
    "pickle.dump( regional_venue_set, open( city+\"/regional_venue_set.pickle\", \"wb\" ) )\n",
    "pickle.dump( regional_subset, open( city+\"/regional_subset.pickle\", \"wb\" ) )\n",
    "pickle.dump( regional_subset_id, open( city+\"/regional_subset_id.pickle\", \"wb\" ) )\n",
    "pickle.dump( master_genre_map, open( city+\"/master_genre_map.pickle\", \"wb\" ) )\n",
    "pickle.dump( event_ids, open( city+\"/event_ids.pickle\", \"wb\" ) )\n",
    "pickle.dump( regional_good_venues, open( city+\"/regional_good_venues.pickle\", \"wb\" ) )\n",
    "\n",
    "'''\n",
    "cur.execute(\"CREATE TABLE events\"\n",
    "            \"(pid INT PRIMARY KEY AUTO_INCREMENT, \"\n",
    "            \"evt_id INT, \"\n",
    "            \"evt_name VARCHAR(400), \"\n",
    "            \"venue_name VARCHAR(150), \"\n",
    "            \"venue_id INT, \"\n",
    "            \"city_name VARCHAR(50), \"\n",
    "            \"metro_id INT, \"\n",
    "            \"latitude VARCHAR(20), \"\n",
    "            \"longitude VARCHAR(20), \"\n",
    "            \"evt_url VARCHAR(200), \"\n",
    "            \"artist VARCHAR(200), \"\n",
    "            \"artist_id INT, \"\n",
    "            \"artist_billing VARCHAR(100) ) \"\n",
    "            )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot events per venue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "hold_vecs = []\n",
    "for key, val in venue_count.iteritems():\n",
    "    hold_vecs.append(val)\n",
    "\n",
    "hold_vecs.sort(reverse=True)\n",
    "\n",
    "plt.bar(range(len(hold_vecs)), hold_vecs )\n",
    "\n",
    "plt.title(\"Events per venue (SD)\")\n",
    "plt.xlabel(\"Venue\")\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot magnitude of venues' vector \n",
    "\n",
    "hold_vecs = []\n",
    "#for key, val in regional_venue_set.iteritems(): # Before > 4 cuts\n",
    "for key, val in regional_good_venues.iteritems(): # After cuts\n",
    "    hold_vecs.append(np.sqrt(val.dot(val)))\n",
    "\n",
    "hold_vecs.sort(reverse=True)\n",
    "\n",
    "plt.bar(range(len(hold_vecs)), hold_vecs )\n",
    "\n",
    "plt.title(\"Genre Magnitude per Venue\")\n",
    "plt.xlabel(\"Venue\")\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel(\"Vector length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#########\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"Total number of venue names =\", len(venue_list)\n",
    "print \"Total number of venue ids =\", len(venue_ids)\n",
    "print \"Total number of master venues =\", len(master_venue_vect)\n",
    "print \"Total number of lat/lons =\", len(locations)\n",
    "pickle.dump( venue_list, open( \"venue_list.pickle\", \"wb\" ) )\n",
    "pickle.dump( venue_ids, open( \"venue_ids.pickle\", \"wb\" ) )\n",
    "pickle.dump( locations, open( \"locations.pickle\", \"wb\" ) )\n",
    "pickle.dump( genre_map, open( \"genre_map.pickle\", \"wb\" ) )\n",
    "\n",
    "del venue_ids[0]\n",
    "del venue_list[0] # oops\n",
    "del locations[0]\n",
    "\n",
    "plotting = master_venue_vect\n",
    "    \n",
    "# Let's normalize all genre vectors for venues\n",
    "for i in range(len(master_venue_vect)):\n",
    "    sum_sq = 0\n",
    "    for component in master_venue_vect[i]:\n",
    "        sum_sq += component*component\n",
    "    denom = math.sqrt(sum_sq)\n",
    "    # Now go back through and divide each by denom\n",
    "    for j in range(len(master_venue_vect[i])):\n",
    "        master_venue_vect[i][j] = master_venue_vect[i][j]/denom\n",
    "\n",
    "\n",
    "pickle.dump( master_venue_vect, open( \"master_venues.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hold_vecs = [0] * len(master_venue_vect[0])\n",
    "for i in range(len(master_venue_vect)):\n",
    "    for j in range(len(hold_vecs)):\n",
    "        hold_vecs[j] += master_venue_vect[i][j]\n",
    "\n",
    "hold_vecs.sort(reverse=True)\n",
    "#print hold_vecs\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "#plt.hist(hold_vecs, bins=len(hold_vecs), histtype='stepfilled', normed=False, color='b', label='Gaussian')\n",
    "plt.bar(range(len(hold_vecs)), hold_vecs )\n",
    "\n",
    "#plt.xlabel('Smarts')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title(r'$\\mathrm{Histogram\\ of\\ IQ:}\\ \\mu=100,\\ \\sigma=15$')\n",
    "#plt.axis([40, 160, 0, 0.03])\n",
    "#plt.grid(True)\n",
    "plt.title(\"Genre Presence\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.ylabel(\"Net frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
