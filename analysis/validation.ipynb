{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Prediction\\n\\n# FUnctions\\ndef norm1(v):\\n    scaled_vector = []\\n    total_A = float(sum(v))\\n    if total_A == 0:\\n        return None\\n    for i in v:\\n        scaled_vector.append(i/total_A)\\n    return scaled_vector\\n\\n#artists = []\\n#corrvens = []\\n#for venue_set in test_set:\\n#    artists.append(venue_set[3])\\n#    corrvens.append(venue_set[2])\\n\\n\\ntoken = \\'WL4JBSOI4ZGXPY8FN\\'\\nquery_params = { \\'api_key\\': token,\\n                 \\'name\\': \"\",\\n                 \\'bucket\\': \\'familiarity\\',\\n                 \\'bucket\\': \\'terms\\'}\\n\\nendpoint = \\'http://developer.echonest.com/api/v4/artist/profile?\\'\\n\\ncount_success = 0\\ncount_all = 0\\n\\nfor i in range(len(xartists)):\\n\\n    hold_my_ven = xvenue_ids[i]\\n    query_params[\\'name\\'] = xartists[i] #artist.lstrip().rstrip()\\n\\n    response = requests.get(endpoint, params=query_params)\\n    full_data = response.json()\\n\\n    if response.json()[\\'response\\'][\\'status\\'][\\'message\\'] != \\'Success\\':\\n        continue\\n\\n    terms = full_data[\\'response\\'][\\'artist\\'][\\'terms\\']\\n    #pretty_artist_names.append(full_data[\\'response\\'][\\'artist\\'][\\'name\\'])\\n    genre_vec = [0] * len(master_genre_map)\\n    # Loop over genres, make vector of frequencies\\n    for term in terms:\\n        # Get index of genre in master_genre_map\\n        indx = getIndex(term[\\'name\\'], master_genre_map)\\n        if indx is None:\\n            continue\\n        # Set corresponding vector entry to value of frequency\\n        genre_vec[indx] = term[\\'frequency\\']\\n    if norm1(genre_vec) is None:\\n        continue\\n    # Set key to artist name, value is array of (normalized) freqs\\n    scaled_vec = np.array(norm1(genre_vec))\\n    # Apply tf-idf\\n    tfidf = scaled_vec*master_genre_idf\\n    # Last step, normalize vector:\\n    user_artist_vec = tfidf/np.linalg.norm(tfidf)\\n    p_index = k_means.predict(user_artist_vec)\\n    \\n    venues = []\\n    for i in range(len(master_venue_list)):\\n        if k_means.labels_[i] == p_index[0]:\\n            \\n            ind = getIndex(master_venue_list[i], venue_list)\\n            venues.append(venue_ids[ind])\\n    count_all += 1\\n    \\n    #print \"This venue = %s\" % hold_my_ven \\n    #print \"Cluster:\", venues\\n    \\n    if xvenue_ids[i] in venues:\\n        count_success += 1\\n\\nprint count_success\\nprint count_all\\n                    \\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pymysql as mdb\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import requests\n",
    "\n",
    "city = \"SF\"\n",
    "\n",
    "master_genre_map = pickle.load( open( city+\"/master_genre_map.pickle\", \"rb\" ) )\n",
    "regional_subset = pickle.load( open( city+\"/regional_subset.pickle\", \"rb\" ) )\n",
    "master_genre_idf = pickle.load( open( city+\"/master_genre_idf.pickle\", \"rb\" ) )\n",
    "\n",
    "def getArtists(evt_id):\n",
    "    token = 'WGLTwENb36bAgHNc'\n",
    "    query_params = { 'apikey': token,\n",
    "                     'per_page': 50,\n",
    "                     'page': 1}\n",
    "    endpoint = 'http://api.songkick.com/api/3.0/events/'+str(evt_id)+'.json?'\n",
    "    response = requests.get(endpoint, params=query_params)\n",
    "    full_data = response.json()['resultsPage']['results']['event']['performance']['artist']\n",
    "    print full_data\n",
    "\n",
    "# For artist subset in one metro region\n",
    "regional_venue_set = dict()\n",
    "region = '26330' # LA=17835, SF=26330, Chicago=9426, SD=11086\n",
    "\n",
    "con = mdb.connect('localhost', 'root', '', 'scenehash', autocommit=True, charset='utf8', use_unicode=True) \n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT evt_id, venue_name, venue_id, artist FROM events WHERE metro_id = %s\" % (region))\n",
    "all_events = list(cur.fetchall())\n",
    "\n",
    "# Storage stuff\n",
    "venue_list = []\n",
    "venue_count = dict()\n",
    "venue_ids = []\n",
    "event_ids = []\n",
    "\n",
    "artist_venue_pair = []\n",
    "rand_cnt = 0\n",
    "#for evtid, ven_name, ven_id, artist_name, lat, lon in all_events:\n",
    "for evtid, ven_name, ven_id, artist_name in all_events:\n",
    "    if ven_id is None:\n",
    "        continue\n",
    "    rand_cnt += 1\n",
    "    if rand_cnt % 20 == 0:\n",
    "        try:\n",
    "            artist_venue_pair.append([ven_id, ven_name, regional_subset[artist_name]/np.linalg.norm(regional_subset[artist_name])])\n",
    "            continue\n",
    "        except Exception:\n",
    "            continue\n",
    "    if ven_name not in regional_venue_set:\n",
    "        venue_list.append(ven_name)\n",
    "        venue_count[ven_name] = 1\n",
    "        venue_ids.append(ven_id)\n",
    "        event_ids.append(evtid)\n",
    "        regional_venue_set[ven_name] = np.array([0.] * len(master_genre_map))\n",
    "    try:\n",
    "        regional_venue_set[ven_name] +=  regional_subset[artist_name]\n",
    "        venue_count[ven_name] += 1\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Let's keep only those venue with 2 > events\n",
    "regional_good_venues = dict()\n",
    "for key, val in regional_venue_set.iteritems():\n",
    "    if venue_count[key] > 3:\n",
    "        regional_good_venues[key] = val\n",
    "\n",
    "test_set = []\n",
    "for artist in artist_venue_pair:\n",
    "    if artist[1] in regional_good_venues:\n",
    "        test_set.append([artist[0], artist[2]])\n",
    "\n",
    "# Test set ready for prediction\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getIndex(element, my_list):\n",
    "    # Create a generator\n",
    "    gen = (i for i,x in enumerate(my_list) if x == element)\n",
    "    for i in gen:\n",
    "        return i\n",
    "\n",
    "# Let's prepare the master_venue_vect:\n",
    "master_venue_vect = []\n",
    "master_venue_list = []\n",
    "master_venue_locs = []\n",
    "\n",
    "for key, val in regional_good_venues.iteritems():\n",
    "    master_venue_vect.append(val)\n",
    "    master_venue_list.append(key)\n",
    "\n",
    "## Let's normalize all genre vectors for venues\n",
    "for i in range(len(master_venue_vect)):\n",
    "    master_venue_vect[i] = master_venue_vect[i]/np.linalg.norm(master_venue_vect[i])\n",
    "\n",
    "X_ven = np.array(master_venue_vect)\n",
    "all_of_them = []\n",
    "\n",
    "k_rng = range(15,16)\n",
    "\n",
    "for k in k_rng:\n",
    "    k_means = cluster.KMeans(n_clusters=k,  init='k-means++', max_iter=250, n_init=20,)\n",
    "    k_means.fit(X_ven) \n",
    "\n",
    "    # Index = cluster number, append to list of venues\n",
    "    clustered_venue_names = []\n",
    "    clustered_venue_ids = []\n",
    "    #print k_means.labels_\n",
    "    # For loop over clusters\n",
    "    for cluster_num in range(k):\n",
    "        temp1 = [] # names\n",
    "        temp2 = [] # ids\n",
    "        for i in range(len(master_venue_vect)):\n",
    "            if k_means.labels_[i] == cluster_num:\n",
    "                #print \"Here in cluster number:\", cluster_num, i, venue_list[i]\n",
    "                temp1.append(master_venue_list[i])\n",
    "                temp2.append(venue_ids[i])\n",
    "        clustered_venue_names.append(temp1)\n",
    "        clustered_venue_ids.append(temp2)\n",
    "    #print clustered_venues\n",
    "    \n",
    "    # Let's compute some metrics\n",
    "    hold_x_vals = []\n",
    "    for i in range(len(clustered_venue_names)):\n",
    "        hold_x_vals.append(len(clustered_venue_names[i]))\n",
    "    # append average venue number, standard dev\n",
    "    lng_of_them.append( np.mean(np.array(hold_x_vals)) )\n",
    "    std_of_them.append( np.std(np.array(hold_x_vals)) )\n",
    "\n",
    "# Predict\n",
    "total_artists = 0\n",
    "gotcha = 0\n",
    "for arto in test_set:\n",
    "    true_ven = arto[0]\n",
    "    p_index = k_means.predict(arto[1])\n",
    "    loc_venues= []\n",
    "    for i in range(len(master_venue_list)):\n",
    "        if k_means.labels_[i] == p_index[0]:\n",
    "            ind = getIndex(master_venue_list[i], venue_list)\n",
    "            loc_venues.append(venue_ids[ind])\n",
    "    \n",
    "    total_artists += 1\n",
    "    if true_ven in loc_venues:\n",
    "        gotcha += 1\n",
    "\n",
    "        \n",
    "print gotcha\n",
    "print total_artists\n",
    "    \n",
    "\n",
    "'''\n",
    "# Prediction\n",
    "\n",
    "# FUnctions\n",
    "def norm1(v):\n",
    "    scaled_vector = []\n",
    "    total_A = float(sum(v))\n",
    "    if total_A == 0:\n",
    "        return None\n",
    "    for i in v:\n",
    "        scaled_vector.append(i/total_A)\n",
    "    return scaled_vector\n",
    "\n",
    "#artists = []\n",
    "#corrvens = []\n",
    "#for venue_set in test_set:\n",
    "#    artists.append(venue_set[3])\n",
    "#    corrvens.append(venue_set[2])\n",
    "\n",
    "\n",
    "token = 'WL4JBSOI4ZGXPY8FN'\n",
    "query_params = { 'api_key': token,\n",
    "                 'name': \"\",\n",
    "                 'bucket': 'familiarity',\n",
    "                 'bucket': 'terms'}\n",
    "\n",
    "endpoint = 'http://developer.echonest.com/api/v4/artist/profile?'\n",
    "\n",
    "count_success = 0\n",
    "count_all = 0\n",
    "\n",
    "for i in range(len(xartists)):\n",
    "\n",
    "    hold_my_ven = xvenue_ids[i]\n",
    "    query_params['name'] = xartists[i] #artist.lstrip().rstrip()\n",
    "\n",
    "    response = requests.get(endpoint, params=query_params)\n",
    "    full_data = response.json()\n",
    "\n",
    "    if response.json()['response']['status']['message'] != 'Success':\n",
    "        continue\n",
    "\n",
    "    terms = full_data['response']['artist']['terms']\n",
    "    #pretty_artist_names.append(full_data['response']['artist']['name'])\n",
    "    genre_vec = [0] * len(master_genre_map)\n",
    "    # Loop over genres, make vector of frequencies\n",
    "    for term in terms:\n",
    "        # Get index of genre in master_genre_map\n",
    "        indx = getIndex(term['name'], master_genre_map)\n",
    "        if indx is None:\n",
    "            continue\n",
    "        # Set corresponding vector entry to value of frequency\n",
    "        genre_vec[indx] = term['frequency']\n",
    "    if norm1(genre_vec) is None:\n",
    "        continue\n",
    "    # Set key to artist name, value is array of (normalized) freqs\n",
    "    scaled_vec = np.array(norm1(genre_vec))\n",
    "    # Apply tf-idf\n",
    "    tfidf = scaled_vec*master_genre_idf\n",
    "    # Last step, normalize vector:\n",
    "    user_artist_vec = tfidf/np.linalg.norm(tfidf)\n",
    "    p_index = k_means.predict(user_artist_vec)\n",
    "    \n",
    "    venues = []\n",
    "    for i in range(len(master_venue_list)):\n",
    "        if k_means.labels_[i] == p_index[0]:\n",
    "            \n",
    "            ind = getIndex(master_venue_list[i], venue_list)\n",
    "            venues.append(venue_ids[ind])\n",
    "    count_all += 1\n",
    "    \n",
    "    #print \"This venue = %s\" % hold_my_ven \n",
    "    #print \"Cluster:\", venues\n",
    "    \n",
    "    if xvenue_ids[i] in venues:\n",
    "        count_success += 1\n",
    "\n",
    "print count_success\n",
    "print count_all\n",
    "                    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
